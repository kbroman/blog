<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Big Data on the stupidest thing...</title>
    <link>https://kbroman.org/blog/tags/big-data/</link>
    <description>Recent content in Big Data on the stupidest thing...</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>The text in this work is licensed under CC-BY-4.0, https://creativecommons.org/licenses/by/4.0/legalcode; code licensed under the MIT License</copyright>
    <lastBuildDate>Thu, 11 May 2017 23:50:00 -0500</lastBuildDate>
    
	<atom:link href="https://kbroman.org/blog/tags/big-data/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>reading/writing biggish data, revisited</title>
      <link>https://kbroman.org/blog/2017/05/11/reading/writing-biggish-data-revisited/</link>
      <pubDate>Thu, 11 May 2017 23:50:00 -0500</pubDate>
      
      <guid>https://kbroman.org/blog/2017/05/11/reading/writing-biggish-data-revisited/</guid>
      <description>Matt Dowle encouraged me to follow up on my post about sqlite, feather, and fst. One thing to emphasize is that saveRDS, by default, uses compression. If you use compress=FALSE you can skip that and it goes much faster. See, for example, his post on “Fast csv writing for R”. Also see his slides from a recent presentation on parallel fread.
I’ll first generate the same data that I was using before.</description>
    </item>
    
    <item>
      <title>sqlite, feather, and fst</title>
      <link>https://kbroman.org/blog/2017/04/30/sqlite-feather-and-fst/</link>
      <pubDate>Sun, 30 Apr 2017 14:07:00 -0500</pubDate>
      
      <guid>https://kbroman.org/blog/2017/04/30/sqlite-feather-and-fst/</guid>
      <description>I don’t think I’m unusual among statisticians in having avoided working directly with databases for much of my career. The data for my projects have been reasonably small. (In fact, basically all of the data for my 20 years of projects are on my laptop’s drive.) Flat files (such as CSV files) were sufficient.
But I’ve finally entered the modern era of biggish data. (Why do they call it big data?</description>
    </item>
    
  </channel>
</rss>